<!-- Date: 2025-01-08 -->
<!-- Update Date: 2025-01-08 -->
<!-- File ID: ccfcf7b3-19f7-4f0f-bc52-fe7d8665b9ba -->
<!-- Author: Seoyeon Jang -->

# 개요

**프로메테우스**는 직접 측정값을 **대상 시스템에서 받아다 수집하는 풀링 방식으로 동작한다.**
프로메테우스에서는 측정값을 수집하는 이 과정을 스크래핑(scraping)이라고 한다.
프로메테우스를 실행하면 스크래핑 대상 엔드포인트를 설정해야 한다.
운영 환경의 컨테이너 플랫폼에서는 클러스터에 있는 모든 컨테이너를 찾도록 설정할 수도 있다.
단일 서버의 도커 컴포즈 환경에서는 서비스 목록으로 도커 네트워크의 DNS를 통해 대상 컨테이너를 자동으로 찾는다.

다음은 `image-gallery`애플리케이션의 두 컴포넌트로부터 측정값을 스크래핑하기 위해 필자가 사용한 설정이다.
전역 설정인 global 항목을 보면 스크래핑 간격이 기본값인 10초로 되어있고, 각 컴포넌트마다 스크래핑 작업을 의미하는 job 설정이 정의돼있다.
job 설정은 해당 스크래핑 작업의 이름과 측정값을 수집할 엔드포인트, 대상 컨테이너를 지정하는 정보로 구성된다.
이 설정에는 두가지 유형이 있다.

1. 정적 설정인 static_config
    - 호스트명으로 단일 컨테이너 지정
2. dns_sd_config 로 DNS 서비스 디스커버리 기능
    - 여러 컨테이너를 지정할 수도 있고 스케일링에 따라 대상 컨테이너를 자동으로 확대할 수 있음

다음은 prometheus.yml 파일이다.
```yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: "image-gallery"
    metrics_path: /metrics
    static_configs:
      - targets: [ "image-gallery" ]

  - job_name: "iotd-api"
    metrics_path: /actuator/prometheus
    static_configs:
      - targets: [ "iotd" ]

  - job_name: "access-log"
    metrics_path: /metrics
    dns_sd_configs:
      - names:
          - accesslog:
        type: A
        port: 80
```

이 설정을 따르면 프로메테우스가 10초마다 한번씩 모든 컨테이너에서 측정값을 수집한다. 프로메테우스는 DNS의 응답 중에서 가장 앞에 오는 IP주소를 사용하므로
도커 엔진이 DNS응답을 통해 로드 밸런싱을 적용한 경우 그 컨테이너 모두에서 측정값을 받아올 수 있다. accesslog 컴포넌트의 스크래핑은 여러 IP주소를 상정해 설정됐으므로
모든 컨테이너의 IP주소를 목록으로 만들어 이들 모두에게서 같은 간격으로 측정값을 수집한다. 다음은 실제 스크래핑이 일어나는 과정이다.

![](.측정값_수집을_맡을_프로메테우스_컨테이너_실행하기_images/9d4eeef1.png)
필자는 `image-gallery`애플리케이션을 위해 따로 설정된 프로메테우스 도커 이미지를 만들어두었다. 이 이미지는 프로메테우스의 공식 이미지를 기반으로 필자의 설정 파일을 추가한 것이다.

```dockerfile
FROM diamol/prometheus
COPY prometheus.yml /etc/prometheus/prometheus.yml
```

이런 방법으로 원하는 설정값이 기본값으로 포함된 프로메테우스 이미지를 만들면 매번 추가로 설정을 작성하지 않아도 되며, 필요한 경우에는 기본값을 수정할 수 있다.

측정값은 여러 컨테이너에서 수집할 때 한층 더 흥미롭다. `image-gallery`애플리케이션의 **Node.js 컴포넌트를 스케일링**해 컨테이너의 수를 증가시키면
프로메테우스가 이들 컨테이너 모두에서 측정값을 수집한다.

>실습: 연습문제 디렉토리에는 또 다른 도커 컴포즈파일이 있다. 이 파일은 access-log 서비스의 공개 포트를 무작위로 설정하기 때문에 해당 서비스에 스케일링을 
> 적용할 수 있다. 세 개의 컨테이너로 이 서비스를 실행하고 웹 애플리케이션에서 부하를 가해보자.

```shell
$ docker-compose -f docker-compose-scale.yml up -d --scale accesslog=3
```

```shell
# 반복문을 돌며 다섯번의 HTTP GET 요청을 보낸다
$ for i in {1..5}; do curl http://localhost:8010 > /dev/null; done;
```



# 정리


